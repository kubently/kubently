# Kubently Environment Configuration
# Copy this file to .env and update with your values

# Server Configuration
HOST=0.0.0.0
PORT=8080
DEBUG=false
LOG_LEVEL=INFO

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50

# API Security
API_KEYS=dev-key-1,service:dev-key-2
AGENT_TOKEN_KUBENTLY=agent-secret-token

# A2A Configuration
A2A_ENABLED=true
A2A_SERVER_DEBUG=false

# LLM Provider Configuration
# Choose your LLM provider: openai, anthropic, azure_openai
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7

# Anthropic Configuration (alternative)
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Azure OpenAI Configuration (alternative)
# LLM_PROVIDER=azure_openai
# AZURE_OPENAI_API_KEY=your-azure-key-here
# AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Kubently API Configuration (for A2A agent)
KUBENTLY_API_URL=http://localhost:8080
KUBENTLY_API_KEY=internal-a2a-key

# Session Configuration
SESSION_TTL=300
SESSION_KEEPALIVE_EXTENSION=300

# Command Configuration
COMMAND_TIMEOUT=10
MAX_COMMAND_TIMEOUT=30
RESULT_TTL=60

# Queue Configuration
MAX_COMMANDS_PER_FETCH=10
LONG_POLL_TIMEOUT=30
QUEUE_BLOCKING_TIMEOUT=1

# Performance Configuration
MAX_CONCURRENT_SESSIONS=100
RATE_LIMIT_PER_MINUTE=1000